[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "딥러닝 (2024)",
    "section": "",
    "text": "질문하는 방법\n\n이메일: guebin@jbnu.ac.kr\n직접방문: 자연과학대학 본관 205호\nZoom: 이메일로 미리 시간을 정할 것\n\n강의노트\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMar 4, 2024\n\n\n01wk-2: 딥러닝의 기초 (1)\n\n\n최규빈 \n\n\n\n\nMar 4, 2024\n\n\n01wk-1: 이미지 자료 분석 (겉핥기)\n\n\n최규빈 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/01wk-1.html#a.-최하니",
    "href": "posts/01wk-1.html#a.-최하니",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "A. 최하니",
    "text": "A. 최하니\n\nhani1 = PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nhani1\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani1)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([2.9308e-09, 1.0000e+00]))\n\n\n\nhani2 = PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani2.jpeg?raw=true').content)\nhani2\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani2)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([8.9153e-06, 9.9999e-01]))\n\n\n\nhani3 = PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani3.jpg?raw=true').content)\nhani3\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani3)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([3.9399e-04, 9.9961e-01]))"
  },
  {
    "objectID": "posts/01wk-1.html#b.-인터넷-고양이",
    "href": "posts/01wk-1.html#b.-인터넷-고양이",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "B. 인터넷 고양이",
    "text": "B. 인터넷 고양이\n\ncat1 = PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-cat1.png?raw=true').content)\ncat1\n\n\n\n\n\n\n\n\n\nlrnr.predict(cat1)\n\n\n\n\n\n\n\n\n('cat', tensor(0), tensor([1.0000e+00, 2.2026e-11]))\n\n\n\ncat2 = PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-cat2.jpeg?raw=true').content)\ncat2\n\n\n\n\n\n\n\n\n\nlrnr.predict(cat2)\n\n\n\n\n\n\n\n\n('cat', tensor(0), tensor([1.0000e+00, 9.4345e-07]))"
  },
  {
    "objectID": "posts/01wk-1.html#a.-step1-dls데이터-준비",
    "href": "posts/01wk-1.html#a.-step1-dls데이터-준비",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "A. Step1: DLS(=데이터) 준비",
    "text": "A. Step1: DLS(=데이터) 준비\n\ndls = ImageDataLoaders.from_folder(\n    path = './images',\n    train='train',\n    valid_pct = 0.2,\n    item_tfms=Resize(224),\n)\n\n\ndls.show_batch()"
  },
  {
    "objectID": "posts/01wk-1.html#b.-step2-러너생성",
    "href": "posts/01wk-1.html#b.-step2-러너생성",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "B. Step2: 러너생성",
    "text": "B. Step2: 러너생성\n\nlrnr = vision_learner(\n    dls = dls,\n    arch = resnet34,\n    metrics = accuracy\n)"
  },
  {
    "objectID": "posts/01wk-1.html#c.-step3-학습",
    "href": "posts/01wk-1.html#c.-step3-학습",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "C. Step3: 학습",
    "text": "C. Step3: 학습\n\nlrnr.fine_tune(7)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.346890\n0.969989\n0.657534\n00:11\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.734809\n0.817061\n0.698630\n00:10\n\n\n1\n0.581782\n0.937060\n0.739726\n00:11\n\n\n2\n0.426661\n0.901986\n0.835616\n00:12\n\n\n3\n0.332050\n0.899157\n0.835616\n00:10\n\n\n4\n0.263004\n0.844802\n0.849315\n00:10\n\n\n5\n0.220254\n0.762331\n0.849315\n00:11\n\n\n6\n0.185242\n0.716601\n0.849315\n00:11"
  },
  {
    "objectID": "posts/01wk-1.html#d.-step4-예측",
    "href": "posts/01wk-1.html#d.-step4-예측",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "D. Step4: 예측",
    "text": "D. Step4: 예측\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninter = Interpretation.from_learner(lrnr)\ninter.plot_top_losses(16)"
  },
  {
    "objectID": "posts/01wk-1.html#크롤링을-활용한-이미지-자료-분석",
    "href": "posts/01wk-1.html#크롤링을-활용한-이미지-자료-분석",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "#. 크롤링을 활용한 이미지 자료 분석",
    "text": "#. 크롤링을 활용한 이미지 자료 분석\n(1) 두 가지 키워드로 크롤링을 수행하여 이미지자료를 모아라. (키워드는 각자 마음에 드는 것으로 설정할 것, 단 (iu,hynn)는 제외)\n(2) ImageDataLoaders.from_folder() 를 이용하여 dls를 만들고 dls.show_batch()를 이용하여 만들어진 이미지를 확인하라.\n(3) vision_learner()를 이용하여 lrnr를 만들고 lrnr.fine_tune()을 이용하여 학습하라. 이때 모형의 arch는 resnet34를 사용하라.\n(4) requests.get()을 이용하여 (1)의 키워드에 해당하는 새로운 이미지를 한장씩 다운받고 (3)에서 학습한 lrnr를 이용하여 예측하라.\n\n제출은 ipynb파일로 할 것. 혹은 스크린샷을 제출해도 괜찮음."
  },
  {
    "objectID": "posts/01wk-2.html#a.-모형소개",
    "href": "posts/01wk-2.html#a.-모형소개",
    "title": "01wk-2: 딥러닝의 기초 (1)",
    "section": "A. 모형소개",
    "text": "A. 모형소개\n- model: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n- model: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/01wk-2.html#b.-회귀모형에서-데이터-생성",
    "href": "posts/01wk-2.html#b.-회귀모형에서-데이터-생성",
    "title": "01wk-2: 딥러닝의 기초 (1)",
    "section": "B. 회귀모형에서 데이터 생성",
    "text": "B. 회귀모형에서 데이터 생성\n\ntorch.manual_seed(43052)\nones= torch.ones(100).reshape(-1,1)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nX = torch.concat([ones,x],axis=-1)\nW = torch.tensor([[2.5],[4]])\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.5+4*x,'--')"
  },
  {
    "objectID": "posts/01wk-2.html#a.-손실함수",
    "href": "posts/01wk-2.html#a.-손실함수",
    "title": "01wk-2: 딥러닝의 기초 (1)",
    "section": "A. 손실함수",
    "text": "A. 손실함수\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\(loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n- loss 함수의 특징\n\n\\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다.\n\\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다.\n(중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n- 우리의 목표: 이 loss(=8587.6875)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다. (단계2에서 할일은 아님)\n\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다.\n\n적당해보이는 주황색 선을 찾자 \\(\\to\\) \\(loss(w_0,w_1)\\)를 최소로하는 \\((w_0,w_1)\\)의 값을 찾자.\n\n- 수정된 목표: \\(loss(w_0,w_1)\\)를 최소로 하는 \\((w_0,w_1)\\)을 구하라.\n\n단순한 수학문제가 되었다. 이것은 마치 \\(f(x,y)\\)를 최소화하는 \\((x,y)\\)를 찾으라는 것임.\n함수의 최대값 혹은 최소값을 컴퓨터를 이용하여 찾는것을 “최적화”라고 하며 이는 산공교수님들이 가장 잘하는 분야임. (산공교수님들에게 부탁하면 잘해줌, 산공교수님들은 보통 최적화해서 어디에 쓸지보다 최적화 자체에 더 관심을 가지고 연구하심)\n최적화를 하는 방법? 경사하강법"
  },
  {
    "objectID": "posts/01wk-2.html#b.-경사하강법",
    "href": "posts/01wk-2.html#b.-경사하강법",
    "title": "01wk-2: 딥러닝의 기초 (1)",
    "section": "B. 경사하강법",
    "text": "B. 경사하강법\n- 경사하강법 아이디어 (1차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접선) &lt;– 미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n\n\n팁: 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입\n\n\n최종수식: \\(w \\leftarrow w - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n- 경사하강법 아이디어 (2차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접평면) &lt;– 편미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n\n\n팁: 여기서도 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입.\n\n- 경사하강법 = loss를 줄이도록 \\({\\bf W}\\)를 개선하는 방법\n\n업데이트 공식: 수정값 = 원래값 - \\(\\alpha\\) \\(\\times\\) 기울어진크기(=미분계수)\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]